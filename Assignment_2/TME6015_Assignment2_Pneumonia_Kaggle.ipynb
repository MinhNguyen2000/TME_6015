{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneumonia classification from Chest X-Ray data with EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Check (GPU vs CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow is using the GPU:\n",
      "- PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Check if a GPU is available\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(\"TensorFlow is using the GPU:\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"- {gpu}\")\n",
    "else:\n",
    "    print(\"TensorFlow is using the CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\caomi\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\caomi\\.cache\\kagglehub\\datasets\\paultimothymooney\\chest-xray-pneumonia\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_hub as hub # tensorflow_hub is giving some dependency clashes when running in Conda\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the Kaggle dataset, I moved the file to within the project repo for easier data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_path = \"D:\\\\Minh Nguyen\\\\TME_6015\\\\Assignment_2\\\\chest_xray\"   # Home PC\n",
    "# base_path = \"C:\\\\Minh Nguyen\\\\TME_6015\\\\Assignment_2\\\\chest_xray\"   # Laptop\n",
    "# base_path = \"C:\\mnguyen\\TME_6015\\Assignment_2\\chest_xray\"           # Work PC\n",
    "\n",
    "# Find path to the dataset folder\n",
    "current_dir = os.getcwd()\n",
    "base_path = os.path.join(current_dir,'chest_xray')\n",
    "\n",
    "train_dir = os.path.join(base_path,'train')\n",
    "val_dir = os.path.join(base_path,'val')\n",
    "test_dir = os.path.join(base_path,'test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of data in the corresponding categories:\n",
      "{'train_PNEUMONIA': 3106, 'train_NORMAL': 1079, 'val_PNEUMONIA': 777, 'val_NORMAL': 270, 'test_PNEUMONIA': 390, 'test_NORMAL': 234}\n"
     ]
    }
   ],
   "source": [
    "def count_data(train_dir, val_dir, test_dir):\n",
    "    num_data_ = {}\n",
    "    for dir_ in [train_dir, val_dir, test_dir]:\n",
    "        for category_ in [\"PNEUMONIA\",\"NORMAL\"]:\n",
    "            key_ = os.path.basename(dir_)+'_'+category_\n",
    "            value_ = len(os.listdir(os.path.join(dir_, category_)))\n",
    "            num_data_[key_] = value_\n",
    "    return num_data_\n",
    "\n",
    "num_data = count_data(train_dir, val_dir, test_dir)\n",
    "\n",
    "print(\"The number of data in the corresponding categories:\")\n",
    "print(num_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seem that the ratio of training samples to testing samples is acceptable. However, given that there are only 8 validation sample for each category, I will ensure that the train test split is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PNEUMONIA: Adjusted to 3106 train and 777 val images.\n",
      "NORMAL: Adjusted to 1079 train and 270 val images.\n"
     ]
    }
   ],
   "source": [
    "def adjust_train_val_split(train_dir, val_dir, desired_split=0.8, seed=42):\n",
    "    \"\"\"\n",
    "    Adjust the train-validation split for the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_dir (str): Path to the training directory.\n",
    "    - val_dir (str): Path to the validation directory.\n",
    "    - desired_split (float): Desired ratio of train to total data (e.g., 0.8 for 80% train, 20% validation).\n",
    "    - seed (int): Random seed for reproducibility.\n",
    "    \"\"\"\n",
    "    # Set seed for reproducibility\n",
    "    random.seed(seed)\n",
    "    \n",
    "    for category in [\"PNEUMONIA\",\"NORMAL\"]:\n",
    "        train_category_dir = os.path.join(train_dir, category)\n",
    "        val_category_dir = os.path.join(val_dir, category)\n",
    "        \n",
    "        # Ensure the validation category directory exists\n",
    "        os.makedirs(val_category_dir, exist_ok=True)\n",
    "        \n",
    "        # Get lists of images in train and val directories for this category\n",
    "        train_images = os.listdir(train_category_dir)\n",
    "        val_images = os.listdir(val_category_dir)\n",
    "        \n",
    "        # Total number of images for this category\n",
    "        total_images = len(train_images) + len(val_images)\n",
    "        \n",
    "        # Calculate desired number of train and validation images\n",
    "        desired_train_count = int(total_images * desired_split)\n",
    "        desired_val_count = total_images - desired_train_count\n",
    "        \n",
    "        # Adjust train set if necessary\n",
    "        if len(train_images) > desired_train_count:\n",
    "            # Move excess images from train to val\n",
    "            move_count = len(train_images) - desired_train_count\n",
    "            images_to_move = random.sample(train_images, move_count)\n",
    "            for img in images_to_move:\n",
    "                image_to_move_path = os.path.join(train_category_dir, img)\n",
    "                shutil.move(image_to_move_path, val_category_dir)\n",
    "        \n",
    "        elif len(train_images) < desired_train_count:\n",
    "            # Move images from val to train to increase training set\n",
    "            move_count = desired_train_count - len(train_images)\n",
    "            images_to_move = random.sample(val_images, move_count)\n",
    "            for img in images_to_move:\n",
    "                image_to_move_path = os.path.join(val_category_dir, img)\n",
    "                shutil.move(image_to_move_path, train_category_dir)\n",
    "        \n",
    "        print(f\"{category}: Adjusted to {desired_train_count} train and {desired_val_count} val images.\")\n",
    "\n",
    "\n",
    "DESIRED_SPLIT = 0.8\n",
    "adjust_train_val_split(train_dir, val_dir, desired_split=DESIRED_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_PNEUMONIA': 3106,\n",
       " 'train_NORMAL': 1079,\n",
       " 'val_PNEUMONIA': 777,\n",
       " 'val_NORMAL': 270,\n",
       " 'test_PNEUMONIA': 390,\n",
       " 'test_NORMAL': 234}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_data(train_dir, val_dir, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data\n",
    "\n",
    "In the following code block, I will extract the images from the directories of the train, validation, and test set for model training in terms of a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4185 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = (224,224)              # input image dimensions for an EfficientNetB0 model\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1/255,\n",
    "    rotation_range=20,\n",
    "    # width_shift_range=0.1,\n",
    "    # height_shift_range=0.1,\n",
    "    # shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_set_raw = train_generator.flow_from_directory(\n",
    "    train_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1047 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = ImageDataGenerator(rescale=1/255)\n",
    "valid_set_raw = validation_generator.flow_from_directory(\n",
    "    val_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1/255)\n",
    "test_set_raw = test_generator.flow_from_directory(\n",
    "    test_dir, target_size=IMAGE_SIZE, batch_size=BATCH_SIZE, class_mode=\"binary\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_set_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EfficientNetB0-based model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Minh Nguyen\\TME_6015\\Assignment_2\\efficientnet-v2-tensorflow2-imagenet1k-b0-classification-v2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# from keras.models import load_model\n",
    "\n",
    "# Path to your SavedModel directory\n",
    "# model_dir = os.path.join(current_dir,\"efficientnetv2-keras-efficientnetv2_b0_imagenet-v3\")      # .h5 model\n",
    "# model_dir = os.path.join(current_dir,\"efficientnet-tensorflow1-b0-classification-v1\")           # .pb model\n",
    "model_dir = os.path.join(current_dir,\"efficientnet-v2-tensorflow2-imagenet1k-b0-classification-v2\") \n",
    "\n",
    "print(model_dir)\n",
    "\n",
    "# Load the SavedModel with the appropriate tag\n",
    "loaded_model = tf.saved_model.load(model_dir)\n",
    "\n",
    "type(loaded_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: [<tf.Tensor 'input_1:0' shape=(None, None, None, 3) dtype=float32>, <tf.Tensor 'unknown:0' shape=() dtype=resource>, <tf.Tensor 'unknown_0:0' shape=() dtype=resource>, <tf.Tensor 'unknown_1:0' shape=() dtype=resource>, <tf.Tensor 'unknown_2:0' shape=() dtype=resource>, <tf.Tensor 'unknown_3:0' shape=() dtype=resource>, <tf.Tensor 'unknown_4:0' shape=() dtype=resource>, <tf.Tensor 'unknown_5:0' shape=() dtype=resource>, <tf.Tensor 'unknown_6:0' shape=() dtype=resource>, <tf.Tensor 'unknown_7:0' shape=() dtype=resource>, <tf.Tensor 'unknown_8:0' shape=() dtype=resource>, <tf.Tensor 'unknown_9:0' shape=() dtype=resource>, <tf.Tensor 'unknown_10:0' shape=() dtype=resource>, <tf.Tensor 'unknown_11:0' shape=() dtype=resource>, <tf.Tensor 'unknown_12:0' shape=() dtype=resource>, <tf.Tensor 'unknown_13:0' shape=() dtype=resource>, <tf.Tensor 'unknown_14:0' shape=() dtype=resource>, <tf.Tensor 'unknown_15:0' shape=() dtype=resource>, <tf.Tensor 'unknown_16:0' shape=() dtype=resource>, <tf.Tensor 'unknown_17:0' shape=() dtype=resource>, <tf.Tensor 'unknown_18:0' shape=() dtype=resource>, <tf.Tensor 'unknown_19:0' shape=() dtype=resource>, <tf.Tensor 'unknown_20:0' shape=() dtype=resource>, <tf.Tensor 'unknown_21:0' shape=() dtype=resource>, <tf.Tensor 'unknown_22:0' shape=() dtype=resource>, <tf.Tensor 'unknown_23:0' shape=() dtype=resource>, <tf.Tensor 'unknown_24:0' shape=() dtype=resource>, <tf.Tensor 'unknown_25:0' shape=() dtype=resource>, <tf.Tensor 'unknown_26:0' shape=() dtype=resource>, <tf.Tensor 'unknown_27:0' shape=() dtype=resource>, <tf.Tensor 'unknown_28:0' shape=() dtype=resource>, <tf.Tensor 'unknown_29:0' shape=() dtype=resource>, <tf.Tensor 'unknown_30:0' shape=() dtype=resource>, <tf.Tensor 'unknown_31:0' shape=() dtype=resource>, <tf.Tensor 'unknown_32:0' shape=() dtype=resource>, <tf.Tensor 'unknown_33:0' shape=() dtype=resource>, <tf.Tensor 'unknown_34:0' shape=() dtype=resource>, <tf.Tensor 'unknown_35:0' shape=() dtype=resource>, <tf.Tensor 'unknown_36:0' shape=() dtype=resource>, <tf.Tensor 'unknown_37:0' shape=() dtype=resource>, <tf.Tensor 'unknown_38:0' shape=() dtype=resource>, <tf.Tensor 'unknown_39:0' shape=() dtype=resource>, <tf.Tensor 'unknown_40:0' shape=() dtype=resource>, <tf.Tensor 'unknown_41:0' shape=() dtype=resource>, <tf.Tensor 'unknown_42:0' shape=() dtype=resource>, <tf.Tensor 'unknown_43:0' shape=() dtype=resource>, <tf.Tensor 'unknown_44:0' shape=() dtype=resource>, <tf.Tensor 'unknown_45:0' shape=() dtype=resource>, <tf.Tensor 'unknown_46:0' shape=() dtype=resource>, <tf.Tensor 'unknown_47:0' shape=() dtype=resource>, <tf.Tensor 'unknown_48:0' shape=() dtype=resource>, <tf.Tensor 'unknown_49:0' shape=() dtype=resource>, <tf.Tensor 'unknown_50:0' shape=() dtype=resource>, <tf.Tensor 'unknown_51:0' shape=() dtype=resource>, <tf.Tensor 'unknown_52:0' shape=() dtype=resource>, <tf.Tensor 'unknown_53:0' shape=() dtype=resource>, <tf.Tensor 'unknown_54:0' shape=() dtype=resource>, <tf.Tensor 'unknown_55:0' shape=() dtype=resource>, <tf.Tensor 'unknown_56:0' shape=() dtype=resource>, <tf.Tensor 'unknown_57:0' shape=() dtype=resource>, <tf.Tensor 'unknown_58:0' shape=() dtype=resource>, <tf.Tensor 'unknown_59:0' shape=() dtype=resource>, <tf.Tensor 'unknown_60:0' shape=() dtype=resource>, <tf.Tensor 'unknown_61:0' shape=() dtype=resource>, <tf.Tensor 'unknown_62:0' shape=() dtype=resource>, <tf.Tensor 'unknown_63:0' shape=() dtype=resource>, <tf.Tensor 'unknown_64:0' shape=() dtype=resource>, <tf.Tensor 'unknown_65:0' shape=() dtype=resource>, <tf.Tensor 'unknown_66:0' shape=() dtype=resource>, <tf.Tensor 'unknown_67:0' shape=() dtype=resource>, <tf.Tensor 'unknown_68:0' shape=() dtype=resource>, <tf.Tensor 'unknown_69:0' shape=() dtype=resource>, <tf.Tensor 'unknown_70:0' shape=() dtype=resource>, <tf.Tensor 'unknown_71:0' shape=() dtype=resource>, <tf.Tensor 'unknown_72:0' shape=() dtype=resource>, <tf.Tensor 'unknown_73:0' shape=() dtype=resource>, <tf.Tensor 'unknown_74:0' shape=() dtype=resource>, <tf.Tensor 'unknown_75:0' shape=() dtype=resource>, <tf.Tensor 'unknown_76:0' shape=() dtype=resource>, <tf.Tensor 'unknown_77:0' shape=() dtype=resource>, <tf.Tensor 'unknown_78:0' shape=() dtype=resource>, <tf.Tensor 'unknown_79:0' shape=() dtype=resource>, <tf.Tensor 'unknown_80:0' shape=() dtype=resource>, <tf.Tensor 'unknown_81:0' shape=() dtype=resource>, <tf.Tensor 'unknown_82:0' shape=() dtype=resource>, <tf.Tensor 'unknown_83:0' shape=() dtype=resource>, <tf.Tensor 'unknown_84:0' shape=() dtype=resource>, <tf.Tensor 'unknown_85:0' shape=() dtype=resource>, <tf.Tensor 'unknown_86:0' shape=() dtype=resource>, <tf.Tensor 'unknown_87:0' shape=() dtype=resource>, <tf.Tensor 'unknown_88:0' shape=() dtype=resource>, <tf.Tensor 'unknown_89:0' shape=() dtype=resource>, <tf.Tensor 'unknown_90:0' shape=() dtype=resource>, <tf.Tensor 'unknown_91:0' shape=() dtype=resource>, <tf.Tensor 'unknown_92:0' shape=() dtype=resource>, <tf.Tensor 'unknown_93:0' shape=() dtype=resource>, <tf.Tensor 'unknown_94:0' shape=() dtype=resource>, <tf.Tensor 'unknown_95:0' shape=() dtype=resource>, <tf.Tensor 'unknown_96:0' shape=() dtype=resource>, <tf.Tensor 'unknown_97:0' shape=() dtype=resource>, <tf.Tensor 'unknown_98:0' shape=() dtype=resource>, <tf.Tensor 'unknown_99:0' shape=() dtype=resource>, <tf.Tensor 'unknown_100:0' shape=() dtype=resource>, <tf.Tensor 'unknown_101:0' shape=() dtype=resource>, <tf.Tensor 'unknown_102:0' shape=() dtype=resource>, <tf.Tensor 'unknown_103:0' shape=() dtype=resource>, <tf.Tensor 'unknown_104:0' shape=() dtype=resource>, <tf.Tensor 'unknown_105:0' shape=() dtype=resource>, <tf.Tensor 'unknown_106:0' shape=() dtype=resource>, <tf.Tensor 'unknown_107:0' shape=() dtype=resource>, <tf.Tensor 'unknown_108:0' shape=() dtype=resource>, <tf.Tensor 'unknown_109:0' shape=() dtype=resource>, <tf.Tensor 'unknown_110:0' shape=() dtype=resource>, <tf.Tensor 'unknown_111:0' shape=() dtype=resource>, <tf.Tensor 'unknown_112:0' shape=() dtype=resource>, <tf.Tensor 'unknown_113:0' shape=() dtype=resource>, <tf.Tensor 'unknown_114:0' shape=() dtype=resource>, <tf.Tensor 'unknown_115:0' shape=() dtype=resource>, <tf.Tensor 'unknown_116:0' shape=() dtype=resource>, <tf.Tensor 'unknown_117:0' shape=() dtype=resource>, <tf.Tensor 'unknown_118:0' shape=() dtype=resource>, <tf.Tensor 'unknown_119:0' shape=() dtype=resource>, <tf.Tensor 'unknown_120:0' shape=() dtype=resource>, <tf.Tensor 'unknown_121:0' shape=() dtype=resource>, <tf.Tensor 'unknown_122:0' shape=() dtype=resource>, <tf.Tensor 'unknown_123:0' shape=() dtype=resource>, <tf.Tensor 'unknown_124:0' shape=() dtype=resource>, <tf.Tensor 'unknown_125:0' shape=() dtype=resource>, <tf.Tensor 'unknown_126:0' shape=() dtype=resource>, <tf.Tensor 'unknown_127:0' shape=() dtype=resource>, <tf.Tensor 'unknown_128:0' shape=() dtype=resource>, <tf.Tensor 'unknown_129:0' shape=() dtype=resource>, <tf.Tensor 'unknown_130:0' shape=() dtype=resource>, <tf.Tensor 'unknown_131:0' shape=() dtype=resource>, <tf.Tensor 'unknown_132:0' shape=() dtype=resource>, <tf.Tensor 'unknown_133:0' shape=() dtype=resource>, <tf.Tensor 'unknown_134:0' shape=() dtype=resource>, <tf.Tensor 'unknown_135:0' shape=() dtype=resource>, <tf.Tensor 'unknown_136:0' shape=() dtype=resource>, <tf.Tensor 'unknown_137:0' shape=() dtype=resource>, <tf.Tensor 'unknown_138:0' shape=() dtype=resource>, <tf.Tensor 'unknown_139:0' shape=() dtype=resource>, <tf.Tensor 'unknown_140:0' shape=() dtype=resource>, <tf.Tensor 'unknown_141:0' shape=() dtype=resource>, <tf.Tensor 'unknown_142:0' shape=() dtype=resource>, <tf.Tensor 'unknown_143:0' shape=() dtype=resource>, <tf.Tensor 'unknown_144:0' shape=() dtype=resource>, <tf.Tensor 'unknown_145:0' shape=() dtype=resource>, <tf.Tensor 'unknown_146:0' shape=() dtype=resource>, <tf.Tensor 'unknown_147:0' shape=() dtype=resource>, <tf.Tensor 'unknown_148:0' shape=() dtype=resource>, <tf.Tensor 'unknown_149:0' shape=() dtype=resource>, <tf.Tensor 'unknown_150:0' shape=() dtype=resource>, <tf.Tensor 'unknown_151:0' shape=() dtype=resource>, <tf.Tensor 'unknown_152:0' shape=() dtype=resource>, <tf.Tensor 'unknown_153:0' shape=() dtype=resource>, <tf.Tensor 'unknown_154:0' shape=() dtype=resource>, <tf.Tensor 'unknown_155:0' shape=() dtype=resource>, <tf.Tensor 'unknown_156:0' shape=() dtype=resource>, <tf.Tensor 'unknown_157:0' shape=() dtype=resource>, <tf.Tensor 'unknown_158:0' shape=() dtype=resource>, <tf.Tensor 'unknown_159:0' shape=() dtype=resource>, <tf.Tensor 'unknown_160:0' shape=() dtype=resource>, <tf.Tensor 'unknown_161:0' shape=() dtype=resource>, <tf.Tensor 'unknown_162:0' shape=() dtype=resource>, <tf.Tensor 'unknown_163:0' shape=() dtype=resource>, <tf.Tensor 'unknown_164:0' shape=() dtype=resource>, <tf.Tensor 'unknown_165:0' shape=() dtype=resource>, <tf.Tensor 'unknown_166:0' shape=() dtype=resource>, <tf.Tensor 'unknown_167:0' shape=() dtype=resource>, <tf.Tensor 'unknown_168:0' shape=() dtype=resource>, <tf.Tensor 'unknown_169:0' shape=() dtype=resource>, <tf.Tensor 'unknown_170:0' shape=() dtype=resource>, <tf.Tensor 'unknown_171:0' shape=() dtype=resource>, <tf.Tensor 'unknown_172:0' shape=() dtype=resource>, <tf.Tensor 'unknown_173:0' shape=() dtype=resource>, <tf.Tensor 'unknown_174:0' shape=() dtype=resource>, <tf.Tensor 'unknown_175:0' shape=() dtype=resource>, <tf.Tensor 'unknown_176:0' shape=() dtype=resource>, <tf.Tensor 'unknown_177:0' shape=() dtype=resource>, <tf.Tensor 'unknown_178:0' shape=() dtype=resource>, <tf.Tensor 'unknown_179:0' shape=() dtype=resource>, <tf.Tensor 'unknown_180:0' shape=() dtype=resource>, <tf.Tensor 'unknown_181:0' shape=() dtype=resource>, <tf.Tensor 'unknown_182:0' shape=() dtype=resource>, <tf.Tensor 'unknown_183:0' shape=() dtype=resource>, <tf.Tensor 'unknown_184:0' shape=() dtype=resource>, <tf.Tensor 'unknown_185:0' shape=() dtype=resource>, <tf.Tensor 'unknown_186:0' shape=() dtype=resource>, <tf.Tensor 'unknown_187:0' shape=() dtype=resource>, <tf.Tensor 'unknown_188:0' shape=() dtype=resource>, <tf.Tensor 'unknown_189:0' shape=() dtype=resource>, <tf.Tensor 'unknown_190:0' shape=() dtype=resource>, <tf.Tensor 'unknown_191:0' shape=() dtype=resource>, <tf.Tensor 'unknown_192:0' shape=() dtype=resource>, <tf.Tensor 'unknown_193:0' shape=() dtype=resource>, <tf.Tensor 'unknown_194:0' shape=() dtype=resource>, <tf.Tensor 'unknown_195:0' shape=() dtype=resource>, <tf.Tensor 'unknown_196:0' shape=() dtype=resource>, <tf.Tensor 'unknown_197:0' shape=() dtype=resource>, <tf.Tensor 'unknown_198:0' shape=() dtype=resource>, <tf.Tensor 'unknown_199:0' shape=() dtype=resource>, <tf.Tensor 'unknown_200:0' shape=() dtype=resource>, <tf.Tensor 'unknown_201:0' shape=() dtype=resource>, <tf.Tensor 'unknown_202:0' shape=() dtype=resource>, <tf.Tensor 'unknown_203:0' shape=() dtype=resource>, <tf.Tensor 'unknown_204:0' shape=() dtype=resource>, <tf.Tensor 'unknown_205:0' shape=() dtype=resource>, <tf.Tensor 'unknown_206:0' shape=() dtype=resource>, <tf.Tensor 'unknown_207:0' shape=() dtype=resource>, <tf.Tensor 'unknown_208:0' shape=() dtype=resource>, <tf.Tensor 'unknown_209:0' shape=() dtype=resource>, <tf.Tensor 'unknown_210:0' shape=() dtype=resource>, <tf.Tensor 'unknown_211:0' shape=() dtype=resource>, <tf.Tensor 'unknown_212:0' shape=() dtype=resource>, <tf.Tensor 'unknown_213:0' shape=() dtype=resource>, <tf.Tensor 'unknown_214:0' shape=() dtype=resource>, <tf.Tensor 'unknown_215:0' shape=() dtype=resource>, <tf.Tensor 'unknown_216:0' shape=() dtype=resource>, <tf.Tensor 'unknown_217:0' shape=() dtype=resource>, <tf.Tensor 'unknown_218:0' shape=() dtype=resource>, <tf.Tensor 'unknown_219:0' shape=() dtype=resource>, <tf.Tensor 'unknown_220:0' shape=() dtype=resource>, <tf.Tensor 'unknown_221:0' shape=() dtype=resource>, <tf.Tensor 'unknown_222:0' shape=() dtype=resource>, <tf.Tensor 'unknown_223:0' shape=() dtype=resource>, <tf.Tensor 'unknown_224:0' shape=() dtype=resource>, <tf.Tensor 'unknown_225:0' shape=() dtype=resource>, <tf.Tensor 'unknown_226:0' shape=() dtype=resource>, <tf.Tensor 'unknown_227:0' shape=() dtype=resource>, <tf.Tensor 'unknown_228:0' shape=() dtype=resource>, <tf.Tensor 'unknown_229:0' shape=() dtype=resource>, <tf.Tensor 'unknown_230:0' shape=() dtype=resource>, <tf.Tensor 'unknown_231:0' shape=() dtype=resource>, <tf.Tensor 'unknown_232:0' shape=() dtype=resource>, <tf.Tensor 'unknown_233:0' shape=() dtype=resource>, <tf.Tensor 'unknown_234:0' shape=() dtype=resource>, <tf.Tensor 'unknown_235:0' shape=() dtype=resource>, <tf.Tensor 'unknown_236:0' shape=() dtype=resource>, <tf.Tensor 'unknown_237:0' shape=() dtype=resource>, <tf.Tensor 'unknown_238:0' shape=() dtype=resource>, <tf.Tensor 'unknown_239:0' shape=() dtype=resource>, <tf.Tensor 'unknown_240:0' shape=() dtype=resource>, <tf.Tensor 'unknown_241:0' shape=() dtype=resource>, <tf.Tensor 'unknown_242:0' shape=() dtype=resource>, <tf.Tensor 'unknown_243:0' shape=() dtype=resource>, <tf.Tensor 'unknown_244:0' shape=() dtype=resource>, <tf.Tensor 'unknown_245:0' shape=() dtype=resource>, <tf.Tensor 'unknown_246:0' shape=() dtype=resource>, <tf.Tensor 'unknown_247:0' shape=() dtype=resource>, <tf.Tensor 'unknown_248:0' shape=() dtype=resource>, <tf.Tensor 'unknown_249:0' shape=() dtype=resource>, <tf.Tensor 'unknown_250:0' shape=() dtype=resource>, <tf.Tensor 'unknown_251:0' shape=() dtype=resource>, <tf.Tensor 'unknown_252:0' shape=() dtype=resource>, <tf.Tensor 'unknown_253:0' shape=() dtype=resource>, <tf.Tensor 'unknown_254:0' shape=() dtype=resource>, <tf.Tensor 'unknown_255:0' shape=() dtype=resource>, <tf.Tensor 'unknown_256:0' shape=() dtype=resource>, <tf.Tensor 'unknown_257:0' shape=() dtype=resource>, <tf.Tensor 'unknown_258:0' shape=() dtype=resource>, <tf.Tensor 'unknown_259:0' shape=() dtype=resource>, <tf.Tensor 'unknown_260:0' shape=() dtype=resource>, <tf.Tensor 'unknown_261:0' shape=() dtype=resource>, <tf.Tensor 'unknown_262:0' shape=() dtype=resource>, <tf.Tensor 'unknown_263:0' shape=() dtype=resource>, <tf.Tensor 'unknown_264:0' shape=() dtype=resource>, <tf.Tensor 'unknown_265:0' shape=() dtype=resource>, <tf.Tensor 'unknown_266:0' shape=() dtype=resource>, <tf.Tensor 'unknown_267:0' shape=() dtype=resource>, <tf.Tensor 'unknown_268:0' shape=() dtype=resource>, <tf.Tensor 'unknown_269:0' shape=() dtype=resource>, <tf.Tensor 'unknown_270:0' shape=() dtype=resource>, <tf.Tensor 'unknown_271:0' shape=() dtype=resource>, <tf.Tensor 'unknown_272:0' shape=() dtype=resource>, <tf.Tensor 'unknown_273:0' shape=() dtype=resource>, <tf.Tensor 'unknown_274:0' shape=() dtype=resource>, <tf.Tensor 'unknown_275:0' shape=() dtype=resource>, <tf.Tensor 'unknown_276:0' shape=() dtype=resource>, <tf.Tensor 'unknown_277:0' shape=() dtype=resource>, <tf.Tensor 'unknown_278:0' shape=() dtype=resource>, <tf.Tensor 'unknown_279:0' shape=() dtype=resource>, <tf.Tensor 'unknown_280:0' shape=() dtype=resource>, <tf.Tensor 'unknown_281:0' shape=() dtype=resource>, <tf.Tensor 'unknown_282:0' shape=() dtype=resource>, <tf.Tensor 'unknown_283:0' shape=() dtype=resource>, <tf.Tensor 'unknown_284:0' shape=() dtype=resource>, <tf.Tensor 'unknown_285:0' shape=() dtype=resource>, <tf.Tensor 'unknown_286:0' shape=() dtype=resource>, <tf.Tensor 'unknown_287:0' shape=() dtype=resource>, <tf.Tensor 'unknown_288:0' shape=() dtype=resource>, <tf.Tensor 'unknown_289:0' shape=() dtype=resource>, <tf.Tensor 'unknown_290:0' shape=() dtype=resource>, <tf.Tensor 'unknown_291:0' shape=() dtype=resource>, <tf.Tensor 'unknown_292:0' shape=() dtype=resource>, <tf.Tensor 'unknown_293:0' shape=() dtype=resource>, <tf.Tensor 'unknown_294:0' shape=() dtype=resource>, <tf.Tensor 'unknown_295:0' shape=() dtype=resource>, <tf.Tensor 'unknown_296:0' shape=() dtype=resource>, <tf.Tensor 'unknown_297:0' shape=() dtype=resource>, <tf.Tensor 'unknown_298:0' shape=() dtype=resource>, <tf.Tensor 'unknown_299:0' shape=() dtype=resource>, <tf.Tensor 'unknown_300:0' shape=() dtype=resource>, <tf.Tensor 'unknown_301:0' shape=() dtype=resource>, <tf.Tensor 'unknown_302:0' shape=() dtype=resource>, <tf.Tensor 'unknown_303:0' shape=() dtype=resource>, <tf.Tensor 'unknown_304:0' shape=() dtype=resource>, <tf.Tensor 'unknown_305:0' shape=() dtype=resource>, <tf.Tensor 'unknown_306:0' shape=() dtype=resource>, <tf.Tensor 'unknown_307:0' shape=() dtype=resource>, <tf.Tensor 'unknown_308:0' shape=() dtype=resource>, <tf.Tensor 'unknown_309:0' shape=() dtype=resource>, <tf.Tensor 'unknown_310:0' shape=() dtype=resource>, <tf.Tensor 'unknown_311:0' shape=() dtype=resource>, <tf.Tensor 'unknown_312:0' shape=() dtype=resource>, <tf.Tensor 'unknown_313:0' shape=() dtype=resource>, <tf.Tensor 'unknown_314:0' shape=() dtype=resource>, <tf.Tensor 'unknown_315:0' shape=() dtype=resource>, <tf.Tensor 'unknown_316:0' shape=() dtype=resource>, <tf.Tensor 'unknown_317:0' shape=() dtype=resource>, <tf.Tensor 'unknown_318:0' shape=() dtype=resource>, <tf.Tensor 'unknown_319:0' shape=() dtype=resource>, <tf.Tensor 'unknown_320:0' shape=() dtype=resource>, <tf.Tensor 'unknown_321:0' shape=() dtype=resource>, <tf.Tensor 'unknown_322:0' shape=() dtype=resource>, <tf.Tensor 'unknown_323:0' shape=() dtype=resource>, <tf.Tensor 'unknown_324:0' shape=() dtype=resource>, <tf.Tensor 'unknown_325:0' shape=() dtype=resource>, <tf.Tensor 'unknown_326:0' shape=() dtype=resource>, <tf.Tensor 'unknown_327:0' shape=() dtype=resource>, <tf.Tensor 'unknown_328:0' shape=() dtype=resource>, <tf.Tensor 'unknown_329:0' shape=() dtype=resource>, <tf.Tensor 'unknown_330:0' shape=() dtype=resource>, <tf.Tensor 'unknown_331:0' shape=() dtype=resource>, <tf.Tensor 'unknown_332:0' shape=() dtype=resource>, <tf.Tensor 'unknown_333:0' shape=() dtype=resource>, <tf.Tensor 'unknown_334:0' shape=() dtype=resource>, <tf.Tensor 'unknown_335:0' shape=() dtype=resource>, <tf.Tensor 'unknown_336:0' shape=() dtype=resource>, <tf.Tensor 'unknown_337:0' shape=() dtype=resource>, <tf.Tensor 'unknown_338:0' shape=() dtype=resource>, <tf.Tensor 'unknown_339:0' shape=() dtype=resource>, <tf.Tensor 'unknown_340:0' shape=() dtype=resource>, <tf.Tensor 'unknown_341:0' shape=() dtype=resource>, <tf.Tensor 'unknown_342:0' shape=() dtype=resource>, <tf.Tensor 'unknown_343:0' shape=() dtype=resource>, <tf.Tensor 'unknown_344:0' shape=() dtype=resource>, <tf.Tensor 'unknown_345:0' shape=() dtype=resource>, <tf.Tensor 'unknown_346:0' shape=() dtype=resource>, <tf.Tensor 'unknown_347:0' shape=() dtype=resource>, <tf.Tensor 'unknown_348:0' shape=() dtype=resource>, <tf.Tensor 'unknown_349:0' shape=() dtype=resource>, <tf.Tensor 'unknown_350:0' shape=() dtype=resource>, <tf.Tensor 'unknown_351:0' shape=() dtype=resource>, <tf.Tensor 'unknown_352:0' shape=() dtype=resource>, <tf.Tensor 'unknown_353:0' shape=() dtype=resource>, <tf.Tensor 'unknown_354:0' shape=() dtype=resource>, <tf.Tensor 'unknown_355:0' shape=() dtype=resource>, <tf.Tensor 'unknown_356:0' shape=() dtype=resource>, <tf.Tensor 'unknown_357:0' shape=() dtype=resource>, <tf.Tensor 'unknown_358:0' shape=() dtype=resource>, <tf.Tensor 'unknown_359:0' shape=() dtype=resource>]\n",
      "Outputs: [<tf.Tensor 'Identity:0' shape=(None, 1000) dtype=float32>]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: Tensor(\"input_1:0\", shape=(None, None, None, 3), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_extractor\u001b[38;5;241m.\u001b[39minputs)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m, feature_extractor\u001b[38;5;241m.\u001b[39moutputs)\n\u001b[1;32m----> 7\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caomi\\anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\caomi\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:157\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m--> 157\u001b[0m         [\n\u001b[0;32m    158\u001b[0m             functional_utils\u001b[38;5;241m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    160\u001b[0m         ]\n\u001b[0;32m    161\u001b[0m     ):\n\u001b[0;32m    162\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    163\u001b[0m             inputs, outputs\n\u001b[0;32m    164\u001b[0m         )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\caomi\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional.py:158\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Check if the inputs contain any intermediate `KerasTensor` (not\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m# created by tf.keras.Input()). In this case we need to clone the `Node`\u001b[39;00m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# and `KerasTensor` objects to mimic rebuilding a new model from new\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# inputs.  This feature is only enabled in TF2 not in v1 graph mode.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[0;32m    157\u001b[0m         [\n\u001b[1;32m--> 158\u001b[0m             \u001b[43mfunctional_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_input_keras_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(inputs)\n\u001b[0;32m    160\u001b[0m         ]\n\u001b[0;32m    161\u001b[0m     ):\n\u001b[0;32m    162\u001b[0m         inputs, outputs \u001b[38;5;241m=\u001b[39m functional_utils\u001b[38;5;241m.\u001b[39mclone_graph_nodes(\n\u001b[0;32m    163\u001b[0m             inputs, outputs\n\u001b[0;32m    164\u001b[0m         )\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\caomi\\anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\functional_utils.py:48\u001b[0m, in \u001b[0;36mis_input_keras_tensor\u001b[1;34m(tensor)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check if tensor is directly generated from `tf.keras.Input`.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03mThis check is useful when constructing the functional model, since we will\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;124;03m  ValueError: if the tensor is not a KerasTensor instance.\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m node_module\u001b[38;5;241m.\u001b[39mis_keras_tensor(tensor):\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(_KERAS_TENSOR_TYPE_CHECK_ERROR_MSG\u001b[38;5;241m.\u001b[39mformat(tensor))\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mnode\u001b[38;5;241m.\u001b[39mis_input\n",
      "\u001b[1;31mValueError\u001b[0m: Found unexpected instance while processing input tensors for keras functional model. Expecting KerasTensor which is from tf.keras.Input() or output from keras layer call(). Got: Tensor(\"input_1:0\", shape=(None, None, None, 3), dtype=float32)"
     ]
    }
   ],
   "source": [
    "feature_extractor = loaded_model.signatures['serving_default']\n",
    "\n",
    "\n",
    "print(\"Inputs:\", feature_extractor.inputs)\n",
    "print(\"Outputs:\", feature_extractor.outputs)\n",
    "\n",
    "feature_extractor = tf.keras.Model(inputs=feature_extractor.inputs, outputs=feature_extractor.outputs[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frozen = True\n",
    "for variable in loaded_model.variables:\n",
    "    print(variable, variable.trainable)\n",
    "\n",
    "if frozen:\n",
    "    print(\"The model is frozen.\")\n",
    "else:\n",
    "    print(\"The model is not frozen.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Input to this model will be images of dimension IMAGE_SIZE + (3,) extracted from train_dir\n",
    "    layers.Input(shape = IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(\"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"),\n",
    "    # layers.GlobalAveragePooling2D(),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
